>[Знай сложности алгоритмов](https://habr.com/ru/articles/188010/)
# Алгоритмическая сложность
>[Сложность алгоритмов. Разбор Big O](https://habr.com/ru/articles/782608/)

## Big O

Big O - нотация с помощью которой вычисляется зависимость объема входных данных алгоритма и его производительность при худшем раскладе

О - оценка временной сложности (в математике "**O**" используется для обозначения "**order of**" (порядка) и позволяет сравнивать функции роста)
n - размер входящих данных

При оценке сложности алгоритмов часто игнорируются константы и несущественные части, Это делается для получения более общего представления о росте сложности алгоритма.
%% 
Например:
Пусть у нас есть алгоритм с временем выполнения **5n^2 + 3n + 2**.
по **Big O** его сложность будет **O(2^n)**. Для борее точных описаний сложности используются другие нотации описанные ниже
%%

Примеры нотаций Big O
- **O(1):** Константная сложность  - время выполнения алгоритма не зависит от размера входных данных. Например, доступ к элементу массива по индексу.
- **O(log n):** Логарифмическая сложность - время выполнения алгоритма растет медленно с увеличением размера входных данных. Например, [[Алгоритмы#Бинарный поиск|бинарный поиск]] в отсортированном массиве.
- **O(n): Линейная сложность** - время выполнения алгоритма пропорционально размеру входных данных. Например, просмотр всех элементов в массиве (один цикл).
- **O(n log n): Линейно-логарифмическая сложность** - время выполнения алгоритма растет быстрее, чем линейно, но медленнее, чем квадратично. Например, [[Алгоритмы#Cортировка слиянием (merge sort)|cортировка слиянием (merge sort)]].
- **O(n^2): Квадратичная сложность** - время выполнения алгоритма зависит от квадрата размера входных данных. Например, [[Алгоритмы#Cортировка пузырьком (bubble sort)|сортировка пузырьком (bubble sort)]] или 2 вложенных цикла.
- **O(n^3): Кубическая сложность** - время  выполнения алгоритма зависит от размера входных данных в кубе. Например, алгоритмы, которые имеют три вложенных цикла, такие как некоторые методы многомерной обработки данных.
- **O(2^n): экспоненциальная сложность** - Например рекурсивное вычисление чисел Фибоначчи
- **O(n!): Факториальная сложность** - самая высокая степень роста времени выполнения алгоритма. Время выполнения алгоритма растет факториально от размера входных данных. Этот тип сложности встречается, например, при *переборе всех возможных комбинаций элементов*, что делает его чрезвычайно неэффективным для больших значений **n**.


![[График роста O - большое.png]]



## Big Theta (Θ)
Оценивает верхнюю и нижнюю границы временной сложности

Θ(f(n)) - время выполнения алгоритма сверху и снизу ограничено функцией f(n) .

## Big Omega (Ω)
Big Omega (Ω) - оценивает нижнюю границу временной сложности алгоритма

Ω(f(n)) - алгоритм выполнится не быстрее, чем функция f(n)

## Little O (o)
Little O представляет собой верхнюю границу, которая строже, чем Big O. Если f(n) является o(g(n)), это означает, что время выполнения алгоритма ограничивается функцией g(n), но алгоритм работает быстрее, чем g(n).

### Little Omega (ω)
Little Omega представляет собой нижнюю границу, которая строже, чем Big Omega. Если f(n) является ω(g(n)), это означает, что алгоритм работает медленнее, чем g(n), но не медленнее, чем f(n).


# Примеры алгоритмов
## Алгоритмы поиска
### Полный перебор
Алгоритмическая сложность  — O(n)
### Бинарный поиск
Алгоритмическая сложность  — O(log(n))


 

## Cортировки

### Timsort

> [Алгоритм сортировки Timsort] (https://habr.com/ru/companies/infopulse/articles/133303/)
> [Это база. Алгоритмы сортировки для начинающих](https://habr.com/ru/companies/selectel/articles/851206/)

Алгоритмическая сложность  — 

Алгоритм построен на идее, что в реальном мире сортируемый массив данных часто содержат в себе упорядоченные (не важно, по возрастанию или по убыванию) подмассивы. В таких случаях Timsort сильно превосходит остальные алгоритмы

#### Принцип работы:

1. вычисляем minrun - это минимальный размер подмассива на которые будет разбит массив. эксперементальным путем было выявленно что лучше чтобы значение варьировалось от 32 до 64. Исключение если исходный массив меньше 64. тогда minrun = длинна исходного массива

### Cортировка слиянием (merge sort)
Основная идея базируется на[[ парадигме «разделяй и властвуй»]].



![[Cортировка слиянием (merge sort).png]]


### Быстрая сортировка (Quick Sort)
Основная идея базируется на[[ парадигме «разделяй и властвуй»]].


![[Быстрая сортировка (Quick Sort).png]]




### Cортировка пузырьком (bubble sort)

## Деревья
Основные операции в деревьях выполняются за время пропорциональное его высоте.

### двоичное дерево поиска (Binary Search Tree, BST)
Алгоритмическая сложность  — O(log(n))
### B-tree (бинарное сбалансированное дерево)
>[B-tree](https://habr.com/ru/articles/114154/)
>[Почему B-деревья быстрые?](https://habr.com/ru/articles/783012/)

Алгоритмическая сложность  — O(log(n))

является сбалансированным деревом ( минимизируют свою высоту)

Cозданы специально для эффективной работы с дисковой памятью, а точнее — они минимизируют обращения типа ввода-вывода.

### красно-черное дерево

### AVL-дерево

### Декартово дерево